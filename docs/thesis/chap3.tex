\chapter{Implementation}
\label{chap:implementation}

The following section details my implementation of behavioral genetic programming.  It follows the details  presented by Krawiec et al. \cite{krawiec}, with several adaptions in order to explore several variants of BGP.

\section{Codebase}
The codebase that I use for this project was first built for FlexGP \cite{flexgp} and then extended for the implementation of Multiple Regression Genetic Programming (MRGP) \cite{mrgp}.  It is written in the Java programming language.  With simple modifications the codebase could run conventional GP for symbolic regression tasks.  One of the main contributions of my work is the way in which I extended the codebase.  Many of the abstractions that I introduced allow the GP process to be extended in unforeseen ways.

\section{Genetic Programming Run}
During the execution of a genetic programming algorithm, there are three steps associated with any given generation.  The steps are as follows:

\begin{itemize}[noitemsep]
\item \textbf{Initialization/Reproduction}: Generate a new population of programs.  In the first round of evolution, the programs are generated from scratch.  In all subsequent rounds the programs are generated from the programs in the old population.
\item \textbf{Evaluation}: Evaluate all of the programs in the new population.
\item \textbf{Survival}: Select which programs in the combined population will be kept for the next round of evolutionary computation.
\end{itemize}

\subsection{Initialization}
When the GP run is initialized, the first step is to create an initial population of programs.  The number of programs in each generation is specified by the user at the start of the run.  The programs are generated by randomly choosing functions and terminals as children of the parent nodes, until every leaf in the tree is a terminal.  A maximum depth is specified, and the trees are generated such that the trees vary from having a depth of one to the maximum depth.

\subsection{Reproduction}
In all subsequent generations, new programs are generated from the population of programs belonging to the previous generation.  One of the modifications that I made was the introduction of a reproduction operator.  Previously the mutation operator and crossover operator were hardcoded as the only possible operators used to generate new children.  The reproduction operator introduces a method to add children to the new population, which can have many different implementations.  For the purposes of this work, the implementation of the reproduction operator that is used allows mutation, crossover, and archive-based crossover, each with an associated probability of being used, each time new programs are to be generated.  This implementation enables the use of conventional GP by setting the archive-based crossover probability to zero.

\subsubsection{Selection of Programs for Reproduction}
During reproduction, new programs are generated until the population size is reached.  To generate a new program, an old program (or in case of crossover, a pair of old programs) is selected to have one of the reproduction operators applied.  The process by which a program is selected is called \textit{tournament selection}.  A tournament size is specified in the parameters of the GP run.  For a given tournament size $n$, $n$ individuals are drawn uniformly at random from the population, and then compete to determine which individual will have the reproduction operator applied.  The winner of the competition is simply the program with the highest rank based on the NSGA-II algorithm \cite{nsga}.  The NSGA-II algorithm is discussed in Section \ref{section:survival}.

\subsubsection{Reproduction Operators}
The mutation and crossover operations were discussed in Section \ref{section:gp_operators}.  In the implementation of behavioral genetic programming by Krawiec et al., the mutation and crossover points for a given program tree are selected by first choosing the depth of the point uniformly at random from 1 to the depth of the tree, then choosing a node uniformly at random from the given depth.  The third operation, archive-based crossover, works identically to the mutation operator, with the exception of how the new subtrees are generated.  In ordinary mutation, the subtrees are generated in the same manner that each member of the initial population of programs is generated.  However, in archive-based crossover, the subtrees are drawn from an archive, which maintains a weighted distribution over which subtrees will be selected.  The archive is discussed further in section \ref{section:evaluation}.

\subsection{Evaluation}
\label{section:evaluation}
Once a new population of programs is generated, all of the new programs must be evaluated on all of the fitness functions that are being used for the genetic programming run.  Additionally, in the case of behavioral genetic programming, the archive is populated based on a machine learning model that is generated from the trace of each program.  This section details the process by which these steps are accomplished.

\subsubsection{Fitness Function Evaluation}
Another abstraction that I introduced into the codebase is that of a fitness function evaluator.  In conventional genetic programming, the program fitness functions can be evaluated in any order, and all that is needed is the numerical output for each fitness function for each program.  In behavioral genetic programming there are two classes of fitness functions.  The functions in the first class only require the programs themselves to be evaluated.  The fitness functions in conventional genetic programming belong to this class.  The functions in the second class require a machine learning model built on the trace of each program to be evaluated.  For each possible configuration of BGP, a different fitness function evaluator is used, which takes care of the proper order for the fitness functions to be evaluated, and the generation of the model.  The different configurations are discussed in Section \ref{section:setup} and detailed in Appendix \ref{appendix:configuration_parameters}.

%\subsubsection{Fitness Functions}
\subsubsection{Conventional Genetic Programming Fitness Functions}
\label{section:conventional_fitness_functions}
In conventional genetic programming, there are typically two fitness functions used to evaluate a program.  The first is the program error $f$, which is a measure of how close the program output on each data point is to the desired output.  The form of the program error fitness used by Krawiec et al. is given by Equation \ref{eq:program_error}, where $\hat y$ is the output of the program, $y$ is the desired output, and $d_{m}$ denotes the Manhattan distance between the two arguments.  The second fitness function is typically a measure of program size $s$, where smaller programs are considered more fit than larger programs.  The form of the program size fitness used by Krawiec et al. is given by Equation \ref{eq:program_size}, where $|p|$ is the number of nodes in the tree that defines the program.

\begin{equation}
\label{eq:program_error}
f = 1 - \frac{1}{1 + d_{m}(\hat y, y)}
\end{equation}

\begin{equation}
\label{eq:program_size}
s = 1 - \frac{1}{|p|}
\end{equation}

\subsubsection{Behavioral Genetic Programming Fitness Functions}
In behavioral genetic programming there are four fitness functions.  Two are the conventional fitness functions discussed in Section \ref{section:conventional_fitness_functions}.  The remaining fitness functions that are used are the model complexity $c$, given by Equation \ref{eq:model_complexity}, and the model error $e$, given by Equation \ref{eq:model_error}, where $M$ is the output of the machine learning model when it is evaluated on the trace of the program, and $|M|$ is the size of the model.

%The model is discussed further in Section \ref{section:model}.

One of the most expensive operations in the execution of a genetic program is the evaluation of each program on all of the data points.  This step is required for both calculating the program error fitness, and generating the trace of the program.  Therefore, in behavioral genetic programming, the trace for a given program is generated while the program error fitness value is calculated.

\begin{equation}
\label{eq:model_complexity}
c = 1 - \frac{1}{|M|}
\end{equation}

\begin{equation}
\label{eq:model_error}
e = 1 - \frac{1}{1 + d_{m}(M, y)}
\end{equation}

\subsubsection{Model}
\label{section:model}
Once the trace for a given program in the population has been collected the machine learning model can be built.  The purpose of the model is two-fold.  The first is that it introduces additional fitness measures for each program (given by Equations \ref{eq:model_complexity} and \ref{eq:model_error}).  Second, it guides the process of populating the archive.

The algorithm that was used for the model in the original implementation of behavioral genetic programming, by Krawiec et al. was REPTree. \cite{reptree}  REPTree is a decision tree that can be used for both classification and regression tasks.  For each program in the population, a different model is built on the program trace.  In my implementation, one can use different models by writing different implementations for the model interface.

\subsubsection{Archive}
In behavioral genetic programming, an archive is used from which to draw subtrees that are used for archive-based crossover.  The archive is given a maximum capacity, which in the original implementation of Behavioral Programming by Krawiec et al. was set to 50.  After each round of fitness function evaluations, the archive is repopulated in the following way.  First the candidate subtrees are selected based on whether or not their column in the trace was used in the machine learning model.  Each subtree is assigned a weight given by Equation \ref{eq:subtree_weight}, where $e$ is the model error from Equation \ref{eq:model_error} and $|U|$ is the number of distinct columns of the trace used in the model.  Note that all subtrees that are used in a certain model are given the same weight in the archive.  Each generation, after the model has been generated, the candidate subtrees are combined with the pre existing contents of the archive (with the exception of the first generation, as the archive would be empty).  If the number of candidate subtrees combined with the previous contents of the archive is less than the archive capacity, then all of the subtrees are added to the archive.  If the number of candidate subtrees combined with the previous contents of the archive is greater than the capacity of the archive, then subtrees are drawn without replacement with probability proportional to their assigned weights.  Algorithm \ref{pseudocode} illustrates this procedure.  For my implementation I use a modification \cite{samplingnew} of the algorithm introduced by Efraimidis and Spirakis \cite{samplingold} to efficiently draw from a weighted distribution without replacement (Note that Algorithm \ref{pseudocode} does not include the details of this procedure).  When subtrees are drawn from the archive for archive-based crossover, they are drawn from the weighted distribution with replacement.

\begin{equation}
\label{eq:subtree_weight}
w = \frac{1}{(1 + e)|U|}
\end{equation}

\begin{algorithm}
\caption{Populate Archive}\label{pseudocode}
\begin{algorithmic}[1]
\Procedure{PopulateArchive}{}
\For {\textit{subtree}\text{ in }\textit{archive}}
\State $w \gets \text{the weight of }\textit{subtree}$
\State $\text{add (}\textit{subtree,w}\text{) to }\textit{candidateSubtrees}$
\EndFor
\State $\text{clear }\textit{archive}$
\For {\textit{program}\text{ in }\textit{population}}
\State $T \gets \textit{collectTrace(program)}$
\State $\textit{M} \gets \textit{buildModel(T)}$
\State $U \gets \text{subtrees included in } \textit{M}$
\State $w \gets 1/((1 + e)|U|)$
\For {\textit{subtree}\text{ in }\textit{U}}
\State $\text{add (}\textit{subtree,w}\text{) to }\textit{candidateSubtrees}$
\EndFor
%\State $\text{add }$\text{(}\textit{U, w}\text{)}\text{ to }\textit{candidateSubtrees}
\EndFor
\If {|\textit{candidateSubtrees}| $\leq$ \textit{ARCHIVE\_CAPACITY}}
\State $\text{add all }\textit{candidateSubtrees}\text{ to }\textit{archive}$
\Else
\While {\textit{archive.size} $<$ \textit{ARCHIVE\_CAPACITY}}
\State $\textit{subtree} \gets \text{draw from }\textit{candidateSubtrees}$
\State $w \gets \text{the weight of }\textit{subtree}$
\State $\text{remove (}\textit{subtree,w}\text{) from }\textit{candidateSubtrees}$
\State $\text{add (}\textit{subtree,w}\text{) to }\textit{archive}$
\EndWhile
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

One significant implementation detail is that the archive cannot have two subtrees which both have the same output on all of the data points (termed the same \textit{semantics}).  In both the original implementation and my own, if two subtrees have the same semantics, then only the subtree with fewer nodes is kept.  Subtrees are duplicated both when they are added to the archive, and drawn from the archive, to ensure that no two programs have a reference to the same subtree.

\subsection{Survival}
\label{section:survival}
Once all of the fitness functions have been evaluated, and the archive repopulated, only half of the programs from the combination of the old and new generation may be kept.  Given that in conventional genetic programming and behavioral genetic programming there are multiple fitness functions, we cannot simply keep the programs that perform best on the fitness functions.  Many programs may perform well on one metric, at the expense of another.  Therefore the NSGA-II algorithm \cite{nsga} is used to rank all of the programs in the combined population, and only the highest ranking half of the combined population is kept for the next generation.

The NSGA-II algorithm first classifies each program into a series of fronts.  The first front (termed \textit{pareto front}) is defined by all of the programs for which no other program in the population performs better on at least one fitness function, and as well or better on the remaining fitness functions.  Each successive front is defined by first removing the last front from the population, and recomputing the next front on the remaining programs in the same way that the pareto front was computed.  Every program in a given front outranks all programs in all subsequent fronts, and is outranked by all programs in all previous fronts.

Within a given front each program is ranked by its crowding distance.  To compute the crowding distance of an individual program, first all fitness measures are normalized (Note that in BGP we use fitness functions which are already normalized).  Then for each fitness measure, the difference between the fitness of the program with the next highest fitness and the next lowest fitness is computed.  The crowding distance for an individual program is given by the average difference across all fitness measures.  If for a given fitness measure an individual program has either the highest or lowest fitness value in the population, it receives a crowding distance of infinity.  Programs with higher crowding distances outrank programs with lower crowding distances.  The reason for the crowding distance ranking is to increase the diversity of the population.  Programs with higher crowding distances are more dissimilar to other programs in the population.

\section{Extensions to Behavioral Genetic Programming}
\label{section:extensions}
One of the core goals of this work is to explore different extensions and alternative implementations of behavioral genetic programming.  For the purpose of this work I explore several variants of the BGP machine learning model, which are detailed below.

\subsection{Full Population Model}
One of the main ideas that I explore is how the model would perform if instead of training one model on the trace of each program in the population, I train one model for the entire population on the combined traces of all of the programs.  This effectively creates a single trace matrix with the same number of rows but many more columns.  The combined trace matrix represents an extremely high dimensional problem, with uninvestigated correlation of its features.

The idea behind training a model for each individual in the population is twofold.  The first is that the accuracy of the model gives insight into how much information the subtrees in a program encode about the desired output. The second is that knowing which subtrees are used in the model gives insight into which subtrees are more valuable than others.  What it does not tell us is which subtrees will work well with other subtrees in the population.

The motivation behind combining all of the program traces to train a single machine learning model is to hopefully identify groups of subtrees coming from different programs in the population that work well together.  With this method one can populate the archive in the same way as in ordinary BGP, however, one cannot use the additional fitness measures, because each program in the population does not have a distinct model error and model complexity associated with it.

\subsection{Lasso Model}
Another implementation that I explore uses Least Absolute Shrinkage and Selection Operator (Lasso) as the machine learning model.  Instead of training REPTree on the trace of each program in the population, I run the Lasso regression method.  For each feature in the data set on which Lasso is run, it assigns a real valued weight.  The predicted output is given by the inner product of the features in the data set, and the weights assigned by Lasso, plus a real valued offset.  One benefit to Lasso is that it will perform feature selection by assigning some feature weights a value of 0.  In this model, I use the same formula for model error, and I define the size of the model $|M|$ as the number of features with non-zero coefficients.  Only subtrees with corresponding features that are given non-zero weights by Lasso are included in the archive.  I use the absolute value of the weights assigned by Lasso as the weight for each respective subtree in the archive.

\subsection{Scikit Learn Model}
Another implementation of the model interface that I employ uses the Python Scikit Learn DecisionTreeRegressor class for regression.  This model works identically to the model that uses REPTree with the exception of calling an alternative implementation of a decision tree.

\subsection{Randomized Model}
Finally, I use an implementation that is identical to the model used in REPTree, however, for each subtree used in the resulting REPTree decision tree, before being placed in the archive, it is replaced by a subtree drawn uniformly at random from the subtrees in the program.  The purpose of this implementation is not to see whether or not this model performs better than the model that uses the subtrees from REPTree.  Rather, it is used to illuminate how much is gained from populating the archive with the trees that are used by REPTree.
