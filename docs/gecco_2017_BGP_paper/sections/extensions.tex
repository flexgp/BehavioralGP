\section{Exploiting Subprograms}\label{sect:foreground}
What emerges from the details of BGP's successful examples is a strategy:  
\begin{inparaenum}

\item Capture the behavior of \st{s} within a program in a trace matrix $T$.

\item  Regress T as feature data on the desired program outputs and derive a model $M$. 

\item Assign a value of merit $f$ to each \st within $M$. Use this merit to determine whether it should be inserted into an archive. Use a modified crossover that draws subprograms from the archive. 

\item Integrate model error and complexity into program fitness so that subprogram behavior influences selection.
\end{inparaenum} \\

One example of the strategy is realized in \cite{KrawiecGECCO2014} where, in Step~(2), \TODO{a REPTREE implementation} of Decision Tree\TODO{CITE} is used for regression modeling and merit is measured as \TODO{insert formula}.  Following our motivation to understand the impact of model bias on useful subprogram identification and program fitness, we first implement an alternative realization of BGP's strategy by using a \SCIKIT learn implementation\TODO{CITE} for regression modeling. \TODO{State how they differ.} With the \SCIKIT implementation we derive $M_S$ and contrast it to deriving $M$ which for clarity we now denote as $M_R$. 

Next, following our observation that prior work derives useful subtree fitness from a model that references just the feature set of \textit{one} program, we realize Steps~(1) and (4) alternately.  In Step~(1) we first select a set of programs  $U$ from the population. We then form a new kind of trace matrix $T_c$ by column-wise concatenating all $T${'s} of the programs in $U$.  $T_c$ is then passed through Steps~(2) and (3). Step~(4) changes because subprograms in $M$ come from the set $U$ not solely one program. The information we can integrate into program fitness is whether a program contributed a feature to $M$. For this we \TODO{insert new fitness factor}.

%Initially $U$ will be the entire population.
