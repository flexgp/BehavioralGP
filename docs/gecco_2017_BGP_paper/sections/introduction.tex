\newcommand{\st}{subprogram\xspace} 

\section{Introduction}\label{sect:intro}
In GP we want to evolve programs that solve problems of impressive complexity, we know this complexity will take graduated/stages of construction (can't be expected to evolved in the timeframe typical gp solutions now arise) but the compelling problem is how to "tease the construction out of"/"redesign for this with" while continuing to embrace the (compelling) fundamental elements of the algorithm. 

BGP arose from the intuition that GP should judge a program by more than how accurately it matches the desired output descriptions. It introduced the program trace which captures what each sub tree does.

Than, how to identify the value of each subtree based on the trace data?  Create a ML-based model from the trace, with each column/subtree as a feature and each row of trace (a different input example in program space) associated with the input example's desired output as the label/response variable in an appended column.  
Then, how to construct, given this information:
BGP archives to insert behaviorally identified subtrees during crossover 
It got very good results. 

This demonstrates we should look at how a program behaves during execution because partial behavior, if it can be identified and isolated, can be used to direct GP toward better program construction.

In this submission we leverage the progress to date of BGP and we turn to further exploiting the trace information and investigate the value of considering them features in the model.

How sensitive is the paradigm to different sorts of feature identification?

In BGP the subtree's are judged only in conjunction with the program they're from, that is the model only uses a feature set that is  from the program. This limits the features of the models, since every subprogram can syntactically stand alone and be combined with any other subprogram, why not consider them all collectively? Or are they synergistic?  Does the model bias matter?
\newpage
\section{Related Work}\label{sect:rw}

\section{Foreground}\label{sect:foreground}
What emerges from the details of BGP's successful examples is a strategy which can be realized in a number of ways other than the algorithms tried in the original paper.
Steps
\begin{enumerate}
\item Capture the behavior of \st. Currently done with trace matrix T in aggregate for every \st in a program.
\item Assign a value of merit to the \st's behavior. Currently done with one program's T + label and modeling with REPTREE. Use model's fitness. Fitness of REPTREE model is associated with program in options 4A and 4, Fitness of model is also associated with \st selection for archive and estimate of archive fitness.
\item Guide the construction of new programs using high value \st{s} and knowledge of which \st{s} have high value. Currently done with archive crossover and 2 fitness measures from model incorporated into fitness of program during selection for replication.
\end{enumerate}

This contribution explores 2 alternatives to (2). \begin{inparaenum}\item We will ask whether different model algorithms  with different feature selection pressure and model bias have significant impact on fitness and whether implementation difference impacts how many  \st{s} are identified.  \item Give motivation. We will try new aggregated variations on T matrix  (full and some of pop). The aggregations of T motivate different fitness being passed to program from modeling.\end{inparaenum}
Describe the algorithm for 2 Aggregated Trace.


\section{Experiments}\label{sect:experiments}

\subsection{Experimental Data, Parameters}\label{sect:data_sets}

All of the data sets used are defined such that the dependent variable is the output of a particular mathematical function for a given set of inputs.  They are taken from a paper entitled \textit{Genetic Programming Needs Better Benchmarks} by McDermott et al. \cite{benchmarks}  All of the inputs are taken to form a grid on some interval.  Let $E[a, b, c]$ denote $c$ samples equally spaced in the interval $[a,b]$. (Note that McDermott et al. defines $E[a, b, c]$ slightly differently.)  Below is a list of all of the data sets that are used:

\begin{enumerate}[noitemsep]
\item \textbf{Keijzer1}: $0.3x \sin(2 \pi x);$ $x \in E[-1,1,20]$
\item \textbf{Keijzer11}: $x y+\sin((x-1)(y-1));$ $x, y \in E[-3,3,5]$
\item \textbf{Keijzer12}: $x^{4}-x^{3}+\frac{y^{2}}{2}-y;$ $x, y \in E[-3,3,5]$
\item \textbf{Keijzer13}: $6 \sin(x) \cos(y);$ $x, y \in E[-3,3,5]$
\item \textbf{Keijzer14}: $\frac{8}{2 + x^{2} + y^{2}};$ $x,y \in E[-3,3,5]$
\item \textbf{Keijzer15}: $\frac{x^{3}}{5} - \frac{y^{3}}{2} - y - x;$ $x, y \in E[-3,3,5]$
\item \textbf{Keijzer4}: $x^{3} e^{-x} \cos(x) \sin(x) (\sin^{2}(x) \cos(x) - 1);$ $x \in E[0,10,20]$
\item \textbf{Keijzer5}: $\frac{3 x z}{(x - 10) y^{2}};$ $x,y \in E[-1,1,4]; z \in E[1,2,4]$
\item \textbf{Nguyen10}: $2 \sin(x) \cos(y);$ $x,y \in E[0,1,5]$
\item \textbf{Nguyen12}: $x^{4} - x^{3} + \frac{y^{2}}{2} - y;$ $x,y \in E[0,1,5]$
\item \textbf{Nguyen3}: $x^{5} + x^{4} + x^{3} + x^{2} + x;$ $x \in E[-1,1,20]$
\item \textbf{Nguyen4}: $x^{6} + x^{5} + x^{4} + x^{3} + x^{2} + x;$ $x \in E[-1,1,20]$
\item \textbf{Nguyen5}: $\sin(x^{2}) \cos(x) - 1;$ $x \in E[-1,1,20]$
\item \textbf{Nguyen6}: $\sin(x) + \sin(x + x^{2});$ $x \in E[-1,1,20]$
\item \textbf{Nguyen7}: $\ln(x + 1) + \ln(x^{2} + 1);$ $x \in E[0,2,20]$
\item \textbf{Nguyen9}: $\sin(x) + \sin(y^{2});$ $x,y \in E[0,1,5]$
\item \textbf{Sext}: $x^{6} - 2 x^{4} + x^{2};$ $x \in E[-1,1,20]$
\end{enumerate}


\textbf{Fixed Parameters}\label{appendix:fixed_parameters}

\begin{itemize}
\item \textbf{Tournament size}: 4
\item \textbf{Population size}: 100
\item \textbf{Number of Generations}: 250
\item \textbf{Maximum Program Tree Depth}: 17
\item \textbf{Function set}: $\{ +, -, *, /, \log, \exp, \sin, \cos, -x \}$
\item \textbf{Terminal set}: Only the features in the data set.
\item \textbf{Archive Capacity}: 50
\item \textbf{Mutation Rate $\mu$}: 0.1
\item \textbf{Crossover Rate with Archive configuration $\chi$}: 0.0
\item \textbf{Crossover Rate with GP $\chi$}: 0.9
\item \textbf{Archive-Based Crossover Rate $\alpha$}: 0.9
\item REPTREE  algorithm parameters 
\item Scikit learn algorithm parameters
\end{itemize}

We are investigating with 17 symbolic regression benchmarks.\\


First we replicated with REPTREE KK et al's work on the symbolic regression benchmarks. \\
Explain meaning of BGP2A, BGP4, BGP4A\\
Our open source software is available on GIT.\\


\subsection{Feature Selection Sensitivity}\label{sect:ftr-select}


Q1. Does the feature selection bias of the model step matter? 

Describe difference in implementations between Reptree and SKL-RepTree.\\
Need REPTREE and Scikit learn algorithm references and links to their code.

Compare REPTREE TO SICKIT LEARN for BGP 2A, 4a, 4 getting 6 combinations\\
Reference Table~\ref{table:avg_fitness} comparing average program error among BGP2A, BGP4, BGP4A, GP for 17 functions with REPTREE and ScikitLearn implementation.\\
Reference Table~\ref{table:avg_size} showing average program size among BGP2A, BGP4, BGP4A, GP for 17 functions with REPTREE and ScikitLearn implementation.\\
STDEV is in separate table in thesis, how to handle in paper?

Statistical testing required!!


\begin{table*}[ht]
\centering
\begin{adjustbox}{width=1\textwidth}
\small
\begin{tabular}{ c c c c c c c c c c c c c c c c c c c }
\hline\hline
 & & Keij1 & Keij11 & Keij12 & Keij13 & Keij14 & Keij15 & Keij4 & Keij5 & Nguy10 & Nguy12 & Nguy3 & Nguy4 & Nguy5 & Nguy6 & Nguy7 & Nguy9 & Sext \\
 \hline
GP &  & 0.303 & 0.851 & 0.968 & 0.391 & 0.841 & 0.879 & 0.576 & 0.986 & 0.163 & 0.381 & 0.221 & 0.246 & 0.128 & \textbf{0.004} & \textbf{0.077} & 0.108 & 0.076 \\
\hline
BP2A & REPTree & 0.272 & 0.784 & 0.97 & \textbf{0.306} & 0.887 & 0.874 & \textbf{0.344} & 0.974 & 0.13 & 0.352 & 0.225 & 0.247 & 0.033 & 0.101 & 0.119 & 0.069 & 0.054 \\
& SCIKitLearn & & & & & & & & & & & & & & & & & \\
 \hline
BP4 & REPTree & 0.467 & 0.908 & 0.989 & 0.914 & 0.916 & 0.915 & 0.706 & 0.997 & 0.412 & 0.444 & 0.222 & 0.327 & 0.275 & 0.086 & 0.113 & 0.201 & 0.26 \\
 %& Lasso & 0.4 & 0.818 & 0.989 & 0.742 & 0.863 & 0.959 & 0.573 & 0.989 & \textbf{0.09} & 0.431 & 0.434 & 0.558 & 0.171 & 0.243 & 0.284 & 0.184 & 0.18 \\
 & Scikit Learn & 0.32 & \textbf{0.547} & \textbf{0.95} & 0.43 & 0.874 & 0.885 & 0.475 & 0.989 & 0.098 & 0.387 & 0.244 & 0.269 & 0.111 & 0.111 & 0.113 & 0.082 & 0.083 \\
% & Randomized & 0.468 & 0.855 & 0.989 & 0.902 & 0.92 & 0.919 & 0.694 & 0.997 & 0.428 & 0.437 & 0.253 & 0.366 & 0.253 & 0.073 & 0.139 & 0.186 & 0.201 \\
 \hline
BP4A & REPTree & 0.435 & 0.912 & 0.988 & 0.891 & 0.92 & 0.909 & 0.672 & 0.997 & 0.37 & 0.438 & 0.206 & 0.352 & 0.152 & 0.154 & 0.132 & 0.221 & 0.217 \\
% & Scikit Learn & 0.357 & 0.701 & 0.975 & 0.46 & 0.801 & 0.913 & 0.397 & 0.982 & 0.274 & \textbf{0.347} & 0.226 & 0.329 & 0.038 & 0.027 & 0.115 & 0.076 & 0.076 \\
% & Randomized & 0.471 & 0.92 & 0.989 & 0.874 & 0.923 & 0.938 & 0.706 & 0.997 & 0.404 & 0.432 & 0.239 & 0.334 & 0.201 & 0.119 & 0.105 & 0.196 & 0.154 \\
% & Larger Archive & 0.443 & 0.919 & 0.988 & 0.897 & 0.917 & 0.936 & 0.69 & 0.997 & 0.356 & 0.421 & 0.206 & 0.306 & 0.167 & 0.179 & 0.131 & 0.183 & 0.22 \\
% & Different Rates & 0.436 & 0.909 & 0.988 & 0.873 & 0.916 & 0.918 & 0.681 & 0.997 & 0.4 & 0.413 & \textbf{0.186} & 0.375 & 0.135 & 0.123 & 0.127 & 0.303 & 0.212 \\
& SCIKitLearn & & & & & & & & & & & & & & & & & \\
\hline
\end{tabular}
\end{adjustbox}
\caption{Average program error for best of run programs.}
\label{table:avg_fitness}
\end{table*}

\begin{table*}[ht]
\centering
\begin{adjustbox}{width=1\textwidth}
\small
\begin{tabular}{ c c c c c c c c c c c c c c c c c c c }
\hline\hline
 & & Keij1 & Keij11 & Keij12 & Keij13 & Keij14 & Keij15 & Keij4 & Keij5 & Nguy10 & Nguy12 & Nguy3 & Nguy4 & Nguy5 & Nguy6 & Nguy7 & Nguy9 & Sext \\
 \hline
GP &  & 38.33 & 43.57 & 48.97 & 28.1 & 29.1 & 45.77 & 58.1 & 42.83 & 21.2 & 23.47 & 24.7 & 29.9 & 23.67 & 10.67 & 28.63 & 23.53 & 32.97 \\
\hline
BP2A & REPTree & 37.6 & 48.87 & 65.57 & 38.97 & 28.03 & 56.2 & 71.17 & 44.9 & 27.83 & 40.13 & 42.6 & 44.63 & 22.17 & 25.63 & 31.57 & 23.53 & 37.1 \\
 & Full Pop & 67.03 & 67.23 & 119.8 & 52.6 & 48.33 & 120.87 & 92.57 & 71.5 & 57.5 & 56.13 & 64.97 & 61.87 & 32.37 & 44.4 & 51.83 & 47.9 & 65.47 \\
 & Scikit Learn & 41.6 & 44.2 & 40.6 & 24.8 & 43.4 & 74.2 & 63.6 & \textbf{25.2} & 30.6 & 31.6 & 35.8 & 59.6 & 31.4 & 16.6 & 38.0 & 14.2 & 31.0 \\
 & Randomized & 41.77 & 40.13 & 51.53 & 43.97 & 29.63 & 59.7 & 49.7 & 44.57 & 36.27 & 34.0 & 43.17 & 37.2 & 25.17 & 21.83 & 29.5 & 14.13 & 43.03 \\
 & Larger Archive & 38.63 & 38.97 & 66.97 & 43.97 & 26.33 & 57.47 & 75.23 & 44.47 & 33.3 & 38.3 & 32.7 & 40.9 & 21.13 & 22.57 & 31.6 & 31.53 & 43.9 \\
 & Different Rates & 36.53 & 38.33 & 55.97 & 43.0 & 24.97 & 58.13 & 48.13 & 48.77 & 32.77 & 38.0 & 32.47 & 41.93 & 25.9 & 26.67 & 34.33 & 22.8 & 35.27 \\
 \hline
BP4 & REPTree & \textbf{20.27} & \textbf{20.8} & \textbf{27.37} & \textbf{24.47} & \textbf{17.9} & 44.47 & \textbf{22.3} & 51.2 & 17.4 & \textbf{18.97} & 24.93 & 25.2 & 14.87 & 20.5 & 29.47 & 12.17 & 22.87 \\
 & Lasso & 20.87 & 29.13 & 27.93 & 25.9 & 26.9 & \textbf{31.33} & 33.27 & 64.43 & 15.27 & 27.4 & \textbf{22.77} & 20.03 & 17.3 & 13.13 & \textbf{19.27} & 12.13 & \textbf{20.1} \\
 & Scikit Learn & 37.6 & 29.6 & 44.0 & 25.2 & 29.2 & 33.4 & 38.2 & 47.8 & \textbf{13.0} & 26.8 & 25.0 & \textbf{20.0} & 23.0 & \textbf{10.6} & 55.2 & 17.2 & 25.4 \\
% & Randomized & 28.43 & 21.17 & 29.83 & 25.0 & 18.77 & 46.07 & 22.87 & 40.27 & 14.5 & 19.9 & 28.47 & 28.23 & 14.1 & 17.1 & 26.67 & \textbf{9.1} & 21.73 \\
 \hline
BP4A & REPTree & 34.8 & 29.03 & 49.67 & 28.2 & 23.23 & 47.47 & 32.6 & 53.07 & 18.37 & 23.27 & 33.87 & 35.83 & 13.97 & 39.23 & 32.07 & 16.2 & 28.23 \\
 & Scikit Learn & 26.6 & 36.0 & 62.2 & 30.0 & 36.4 & 65.2 & 51.0 & 42.6 & 24.0 & 39.6 & 42.8 & 64.6 & 27.0 & 13.2 & 35.4 & 10.6 & 40.4 \\
 & Randomized & 48.77 & 24.53 & 39.73 & 28.63 & 25.17 & 44.3 & 42.83 & 50.37 & 20.57 & 24.87 & 33.13 & 34.5 & 16.8 & 31.33 & 30.27 & 11.47 & 22.0 \\
 & Larger Archive & 42.4 & 35.37 & 43.17 & 37.03 & 22.17 & 51.8 & 39.33 & 51.03 & 17.1 & 25.4 & 34.63 & 36.03 & \textbf{13.73} & 30.87 & 34.63 & 15.17 & 24.9 \\
 & Different Rates & 38.43 & 28.5 & 41.23 & 29.33 & 25.07 & 52.07 & 36.93 & 56.93 & 19.27 & 27.2 & 33.17 & 37.5 & 15.33 & 34.1 & 29.77 & 15.23 & 34.5 \\
\hline
\end{tabular}
\end{adjustbox}
\caption{Average program size for best of run programs.}
\label{table:avg_size}
\end{table*}

Include a ranking table.  just on error of program and only 6 combinations (two choices of decision tree implementation) and 3 algorithms (2A,4,4A). 

Select 1 run, 1 dataset: what is \# of features in model of best individual at first and final generation (each generation)? What is fraction of \# of features in model to \# of subtrees in best individual at first and final generation (each generation)?  (Each generation) means we would have a plot (fitness on Y1 axis, features/fraction on Y2, Y3 and X is generations). We could amass these statistics for every dataset and 30 runs but lower priority than other tasks.

Segue to next subsection: Do features depend on one another? We're identifying their model value in the context of the same tree. They could be co-adapted and not very good with any other tree. We investigate further.

\subsection{Aggregate Trace Matrices}\label{sect:agg-features}

The question is what aggregations? What if we take everyone?

show discuss results of full-pop (call it 100_XX)\\

Detailed study: take 1 run, 1 dataset (save seed!) and one algorithm of 2A,3,3A and one choice of decision tree.  What dataset? Choices: use hardest problem, or one that 2A,3,3A don't do as well as GP on. \\
How many programs have one or more features in the model?\\ how many programs have 2, 3, etc? This says something about co-adaptation. Were pairs of features subtrees where one was within the other?  \\what is the ratio of model features to total-features-in-pop? \\how many features are in the model (first, final generations?) (maybe plot every generation ( very low priority))

Now what if we discriminate the aggregation set by fitness so we're only identifying features from superior parts of the population?

We create 3 additional  aggregate trace matrices: 25, 50, 75,  where pop is sorted low to high by fitness (error + size) and then cut off at these different thresholds. 

Show/describe a longitudinal comparison of all 4 and add in best of program-trace resutls.

Does the discrimination by program fitness plus the aggregation among programs work better than just program trace? SHOW GRAND RANKING.

\TODO{Insert my sketch of tables of results}

\TODO{Not for Monday night but if we get accepted, we can increase the number of runs and robustness of the detailed results to encompass more datasets or more runs and provide average and standard deviation}



\section{Conclusions and Future Work}\label{sect:conc}
\TODO{Currently unedited...just cut-n-paste from Steven's thesis}
My primary contributions are threefold.

\begin{enumerate}[noitemsep]
\item Provide support for the claims of BGP by Krawiec et al.
\item Create a BGP implementation that is easily extendable for future work related to BGP.
\item Explore numerous extensions to and features of the BGP methodology.
\end{enumerate}

\subsection{Future Work}\label{section:future_work}
A lot of what this work brings to light is particular paths to extend the concepts and understanding of BGP.  Below I detail several avenues to explore.

\subsubsection{Alternate Models}
The primary avenue that this work opens up is the possibility of exploring different models to use in BGP.  It would be interesting to see if using a machine learning model whose purpose is more inline with what BGP asks for would benefit the evolutionary process.  For example, instead of building an entire machine learning model on the trace, one could use a feature selection technique, or measure the statistical correlation between the columns.  The output would provide material with which to populate the archive.  However, this would not provide additional fitness measures.

\subsubsection{Lasso}
Lasso brought several interesting features of BGP to light.  It is important to have a machine learning model that is robust against the pathological inputs that can be generated by a genetic programming algorithm.  It would be interesting to explore why Lasso in general, or at least the implementation that I use has significant trouble for certain inputs.  Additionally, it is interesting that even though running Lasso is the runtime bottle neck, the configurations that took substantially too long to run were BP2A, and BP4A, both of which use an archive.  Understanding precisely why the configurations with an archive produce worse inputs to Lasso could be insightful.

\subsubsection{Mixing Traces}
It is unclear exactly why the BGP model that uses the combined traces of all of the programs in the population performed less well than running the model on each program trace independently.  It is possible that the idea has merit, but the particulars were not a good fit for BGP.  In particular, in each generation only a single machine learning model is built.  Therefore, all of the selected trees put into the archive in a single generation have the same weight.

An alternate implementation would be to draw random subsets from the combined trace of the programs in the population, and build a model on each.  This would create many candidate subtrees with different weights, and possibly a more robust archive, if it can be populated with subtrees that are frequently selected by the machine learning model.

\subsubsection{Subtrees with the Same Semantics}
As is mentioned in Section \ref{section:evaluation} if two subtrees have identical columns in the program trace (i.e. identical \textit{semantics}), only the smaller subtree is kept.  This introduces a bias that is not necessarily beneficial to the evolutionary process.  It would be interesting to explore how common subtrees with identical semantics are, and if choosing the smaller tree is the better choice.

\subsubsection{Combining Reproduction Operators}
It would be interesting to see if combining mutation, crossover, and archive-based crossover could enable better performance than using only two of the reproduction operators.

%\subsubsection{Model Error}
%Comparing the performance of REPTree vs the Scikit Learn decision tree, I find that REPTree typically builds models with much higher errors when run on the trace, while Scikit Learn builds models with near zero error.  It would be interesting to explore what impact this has to the evolutionary process.

\subsubsection{Model Evaluation}
In BGP, after the model is built on the trace of each program, it is evaluated on the trace.  The result of its evaluation is used as the output of one of the fitness functions for the program.  It would be interesting to explore evaluating each model on a test set, instead of the trace.  Perhaps this would yield a more useful fitness function.
